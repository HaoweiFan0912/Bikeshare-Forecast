---
title: "Predicting Bike Usage at UofT St. George with Bayesian Poisson Regression"
subtitle: "Daily usage grows by one every 20 days, drops to between 0 and 3 in winter, with 79% occurring between 8 AM and 8 PM"
author: 
  - Haowei Fan
thanks: "Code and data are available at: https://github.com/HaoweiFan0912/Bikeshare-Forecast.git"
date: today
date-format: long
abstract: "University of Toronto's St. George campus students and staff frequently encounter challenges in locating available bike-sharing parking spots upon arrival and bikes upon leaving [@elassi2017bike], underscoring the necessity for accurate predictions of future bike-sharing demand to optimize campus commuting infrastructure. This study employs Bayesian Poisson regression to predict the utilization of bike-sharing stations at 27 locations across campus for specific years, months, and four-hour intervals of the day. The results show that daily bike-sharing usage on campus increases by one every 20 days but decreases to between 0 and 3 in winter months, and 79% of peak usage consistently observed between 8:00 AM and 8:00 PM daily. Specifically, on September 26, 2025, between 4:00 and 8:00 AM, the usage of 8 stations is projected to increase by 3 bikes, 14 stations by 2 bikes, 3 stations by 1 bike, while 1 station will remain unchanged, and 1 station will see a decrease by 1 bike, compared to the same timeframe in 2024."
format: pdf
toc-depth: 2    
number-sections: true
toc: true           
toc-title: "Table of Contents" 
bibliography: references.bib
---

```{r}
#| echo: false
#| include: false
#| warning: false
#| message: false
#### Workspace setup ####
set.seed(912)
# List of necessary packages
packages <- c("tidyverse", "dplyr", "arrow", "ggplot2", "RColorBrewer", "knitr", "bayesplot", "kableExtra", "scales")
# Install missing packages
missing_packages <- packages[!(packages %in% installed.packages()[, "Package"])]
install.packages(missing_packages)
# Load packages
lapply(packages, library, character.only = TRUE)

#### Read data ####
start <- read_parquet(here::here("data/02-analysis_data/start.parquet"))
stop <- read_parquet(here::here("data/02-analysis_data/stop.parquet"))
```

# Introduction

## Overview
Bike-sharing services have experienced rapid growth in the Toronto region, with ridership rising dramatically from approximately 665,000 trips in 2015 to over 4.5 million in 2022, according to a study by the University of Toronto's School of Cities[@liu2023bike]. This rapid increase highlights the critical need for data-driven analyses to optimize bike-sharing systems and guide policy decisions that can further enhance urban mobility[@xiamen]. While city-wide studies provide valuable suggestions, research from Hangzhou, China, has demonstrated that bike-sharing usage patterns can vary significantly between urban areas and university campuses[@hangzhou]. These differences suggest that general urban studies conducted in the Toronto region may not fully capture the unique dynamics of campus-based bike-sharing systems. Therefore, to address this gap in the literature, this study focuses on the University of Toronto St. George Campus as a case study, analyzing bike-sharing usage within the campus in Toronto to provide a nuanced understanding of its role in campus mobility and inform policies tailored to similar settings.

The estimand of this study aims to predict the usage of a specific bike-sharing station on the University of Toronto campus during a particular 4-hour interval. By transforming time into components such as year, month, day, and the specific 4-hour interval of the day, the analysis incorporates overall trends, seasonal effects, and hourly variations in station usage. The primary objective is to investigate temporal changes in the usage of 27 bike-sharing stations on campus, thereby providing policymakers with recommendations for optimizing bike allocation to enhance commuting efficiency. To achieve this estimand, the study extracts a sample of 27 bike-sharing stations within the University of Toronto campus from all bike-sharing usage data recorded between January 1, 2017, and September 30, 2024. A Bayesian Poisson regression model is then employed to predict station usage based on factors such as station location, year, month, day, and the specific 4-hour interval of the day.

This study found that although the usage at all stations within the University of Toronto campus has increased by an average of one user every 20 days each year, there are significant seasonal differences. During winter, usage at all stations, regardless of the year, remains close to zero between 0 to 3. Additionally, from January to September each year, the usage shows an upward trend, which then gradually declines over the following months. There are also significant differences in usage across different times of the day. The period from 8 am to 8 pm accounts for an average of 79% of daily usage, while the period from midnight to 8 am accounts for only 6%. It is noteworthy that this project forecasts an average increase of 2 uses across 27 stations between 4:00 AM and 8:00 AM on September 26, 2025, compared to the same time period in 2024. Specifically, usage at 8 stations is expected to increase by 3, 14 stations by 2, and 3 stations by 1, while 1 station will remain unchanged and another will decrease by 1.

Compared to the general statistics on bike-sharing usage in the Greater Toronto Area, these findings offer more detailed recommendations specifically for transportation planning and policy adjustments within the University of Toronto St. George campus. They also provide guidance on how to better allocate, deploy, or store shared bikes.

The structure of this paper is as follows: @sec-data outlines the data sources, evaluates the data measurements, introduces key variables along with their visualizations, presents similar datasets, provides a high-level description of the data cleaning process, and details the technical support utilized in this project. @sec-model provides an in-depth explanation of the model types used in this study and the rationale behind the selection. It introduces the target variable, predictors, and all components of the model. This section also includes model validation and discusses an alternative model. @sec-result uses a specific time frame in 2025 as an example to make predictions using the model, comparing the results with 2024 data. @sec-discussion explores the implications of this study for the world, acknowledges its limitations, and offers recommendations for future research.

# Data {#sec-data}

## Overview
The dataset used in this study is named "Bike Share Toronto Ridership Data" [@bikesharedata]. It comes from opendatatoronto [@opendata], uploaded by Toronto Parking Authority[@greenp] and collected by Bike Share Toronto[@bike]. It records every bike-sharing usage in the Toronto area from 2015 to September 30, 2024, with a total of 28,017,329 records. The variables included in the data differ across years, but they all contain the following variables: Trip ID, Trip Duration, Trip Start Station ID, Trip Start Time, Trip Start Station Location, Trip End Station ID, Trip End Time, Trip End Station Location, Bike ID, and User Type.

There are many similar datasets available, but they pose significant limitations in the context of this study. Bike-sharing service providers worldwide have made their operational data publicly available for research purposes. For instance, the Shenzhen Municipal Transport Bureau in China released a dataset containing partial bike-sharing order information from January to August 2021. This dataset includes eight variables: user ID, start time, start longitude, start latitude, end time, end longitude, end latitude, and company ID, with a total of approximately 240 million records [@szdd]. While this dataset offers a rich variety of variables, it has limitations that make it unsuitable for this research. The data only covers an eight-month period, which is insufficient to capture long-term trends in bike-sharing usage. Additionally, university campuses in China are typically closed environments, unlike the open urban settings of Toronto, making the data less generalizable for this study's research context. Similar issues are present in other bike-sharing datasets from different regions. These include limited temporal coverage, which restricts long-term analysis, strong regional characteristics influenced by local cultural habits, and significant variations in data quality and structure due to fierce market competition among bike-sharing companies. These factors make it challenging to integrate data across companies or regions. Therefore, while these datasets may hold value for other studies, they do not meet the requirements of this research.

This study follows the workflow of Telling Stories with Data [@tellingstories], using its initial folder structure and part of its code. Data downloading, cleaning, modeling, and visualization were carried out using R [@citeR]. The following R libraries were also used alongside R:

**tidyverse**[@tidyverse]: Used for data wrangling, cleaning, and analysis, integrating multiple data manipulation packages.

**dplyr**[@dplyr]: Used for data frame operations such as filtering, sorting, and aggregation.

**arrow**[@arrow]: Used for reading and writing data in efficient formats like Parquet to speed up processing.

**stringr**[@stringr]: Used for handling and manipulating strings, allowing for text data cleaning and transformation.

**readr**[@readr]: Used for fast reading of CSV and other text formats.

**lubridate**[@lubridate]: Used for handling and converting date-time data, simplifying time-related data analysis.

**brms**[@brms]: Used for building and estimating Bayesian regression models for flexible data analysis.

**rstanarm**[@rstanarm]: Used for Bayesian regression modeling, helping to understand uncertainty better.

**bayesplot**[@bayesplot]: Used for visualizing posterior distributions and diagnostic plots of Bayesian models.

**ggplot2**[@ggplot2]: Used for creating various types of plots, supporting exploratory data analysis and result presentation.

**RColorBrewer**[@RColorBrewer]: Used for generating color palettes to create visually distinct and appealing plots.

**knitr**[@knitr]: Used for generating dynamic reports, integrating analysis results into documents.

**kableExtra**[@kableExtra]: Used for enhancing the presentation of tables, making tables in reports more visually appealing.

**scales**[@scales]: Used for formatting large numbers.

**reshape2**[@reshape]: Used for reshaping data, particularly converting between wide and long formats

## Measurement
To predict the relationship between bike-sharing usage and time within the University of Toronto's St. George campus, this study requires a time series to describe the changes in usage at different stations over time. Therefore, the "Bike Share Toronto Ridership Data" [@bikesharedata], which spans over eight years to date and documents every instance of bike-sharing usage, including the time and location of each ride, is ideal for this study.

This data is particularly ideal for the study also due to its high reliability, which stems from the commercial nature of bike-sharing operations. The advanced bike-sharing system ensures accurate data collection and management by automatically recording ride information. Each bike and docking station is equipped with sensors and communication devices, enabling the capture of detailed trip data.

However, the raw data cannot be used directly in this project; sophisticated data cleaning is required, with specific steps and reasons as follows: First, data from 2015–2016 was excluded because the collection and recording methods during those years differed significantly from later periods and did not include the time and station variables necessary for this study. Next, data from stations located within the University of Toronto's St. George campus was extracted from the remaining samples to align with the study's objectives. Then, the variables `time` and `count` were constructed to record the total usage at each station within specific four-hour intervals. Finally, the variables of interest were extracted, and the data format was standardized to ensure compatibility for subsequent analysis. The cleaned data is presented in the format shown in @tbl-cleaned_data.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-cleaned_data
#| tbl-cap: "Samples of the dataset used for analysis"


start |>
  tail() |>
  kable(booktabs = TRUE, align = "c")
```



## Variables
This study focuses on the following variables:

- `count`: The dependent variable of the study, a non-negative integer. It describes the total usage of bike-sharing at a particular station during a specific 4-hour interval. This is a constructed variable derived by calculating the total number of uses at a specific station within a given four-hour interval.
- `time`: An independent variable representing the time interval. For example, "2024-09-29 12:00:00" represents the time interval from 12 pm to 4 pm on September 29, 2024, in a 24-hour format. The earliest `time` is "2017-01-01 00:00:00," and the latest is "2024-09-30 24:00:00". This is a constructed variable designed to indicate which four-hour interval the exact trip start time, recorded to the second in the raw data, falls into.
- `station_name`: An independent variable representing the unique name of one of the 27 stations within the University of Toronto's St. George campus.

It is important to note that there may be a relationship between the two independent variables, `time` and `station_name`, as the operating times of different stations might vary. However, this does not affect the validity of the study because the analysis focuses on the usage patterns within the available operational hours for each station, rather than comparing stations with differing start times directly.

@tbl-varibale is the summary of varibales. It is evident that the dataset includes 27 unique station names and spans nearly eight years (from January 1, 2017, to September 30, 2024), providing opportunities to analyze long-term trends and seasonal variations. In the count column, the minimum and median values are both 1, the mean is 2, the first quartile is 1, the third quartile is 3, and the maximum reaches 31, showing a significant right-skewed distribution. This indicates that most of the records have low count values, but there are a few extreme high values.
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-varibale
#| tbl-cap: "Variables' summary"
count_min <- min(start$count)
count_1st_qu <- quantile(start$count, 0.25)
count_median <- median(start$count)
count_mean <- mean(start$count)
count_3rd_qu <- quantile(start$count, 0.75)
count_max <- max(start$count)

summ <- data_frame(station_name = c("Type: Character", "Number of Unique Values: 27", NA, NA, NA, NA),
                   time = c("Earliest: 2017-01-01 04:00:00", "Latest: 2024-09-30 20:00:00", NA, NA, NA, NA),
                   count = c(paste("min:",count_min),
                             paste("1st Qu:",count_1st_qu),
                             paste("median:",count_median),
                             paste("mean:", round(count_mean,0)),
                             paste("3rd Qu:",count_3rd_qu),
                             paste("max:",count_max)))

kable(summ)

```


@fig-daily_usage shows the daily usage totals of 27 shared bicycle stations from January 1, 2017, to September 30, 2024. It can be observed that the usage of the 27 bike-sharing stations at the University of Toronto's St. George campus has shown a steady upward trend, with an average increase of 1 use every 20 days. At the same time, there are clear seasonal variations: usage is higher in the spring and summer months (April to September) and significantly lower in the fall and winter months (October to March). Additionally, there was an abnormal surge in usage from June to September 2024, which can be attributed to two main reasons. First, historical data indicates that usage typically spikes in August and September each year, likely due to increased demand from students returning to campus for the start of the academic year. Second, during the same period in 2024, Bike Share Toronto added 52 new stations, most of which were located near the St. George campus, significantly enhancing the network's coverage and convenience[@bike]. These two factors combined led to the appearance of anomalies in August and September 2024.
```{r, fig.pos="H"}
#| label: fig-daily_usage
#| fig-cap: Daily usage from January 2017 to September 2024
#| echo: false
#| message: false
#| warning: false

start_asdate <- start 
start_asdate$time <- as.Date(start_asdate$time)
daily_counts <- start_asdate %>%
  group_by(time) %>%
  summarise(total_count = sum(count))

lm_model <- lm(total_count ~ time, data = daily_counts)


slope <- coef(lm_model)["time"]

ggplot(data = daily_counts, aes(x = time, y = total_count)) +
  geom_point() +
  labs(x = "Time", y = "Daily usage") +
  theme_minimal() +
  geom_smooth(method = "lm") +
  annotate("text", x = max(daily_counts$time), y = max(daily_counts$total_count), 
           label = paste("Slope =", round(slope, 2)), hjust = 1.3)


```

@fig-timely_usage shows the total usage and percentage of shared bicycles during different time intervals in a day from January 1, 2017, to September 30, 2024. It can be observed that the peak usage occurs between 12:00 to 16:00 (28.5%) and 16:00 to 20:00 (31.4%). The usage between 08:00 to 12:00 accounts for 19.9%, while the usage from 20:00 to 00:00 accounts for 13.4%. The time intervals with the lowest usage are 00:00 to 04:00 (3.6%) and 04:00 to 08:00 (3.2%).

```{r, fig.pos="H"}
#| label: fig-timely_usage
#| fig-cap: Total usage during different time periods from January 2017 to September 2024
#| echo: false
#| message: false
#| warning: false


options(scipen = 999)

start_astime <- start 
start_astime$time <- as.POSIXct(start_astime$time)


start_astime <- start_astime %>%
  mutate(time_interval = case_when(
    hour(time) >= 0 & hour(time) < 4 ~ "00:00 - 04:00",
    hour(time) >= 4 & hour(time) < 8 ~ "04:00 - 08:00",
    hour(time) >= 8 & hour(time) < 12 ~ "08:00 - 12:00",
    hour(time) >= 12 & hour(time) < 16 ~ "12:00 - 16:00",
    hour(time) >= 16 & hour(time) < 20 ~ "16:00 - 20:00",
    hour(time) >= 20 & hour(time) < 24 ~ "20:00 - 00:00"
  ))


total_counts <- start_astime %>%
  group_by(time_interval) %>%
  summarise(count = sum(count, na.rm = TRUE)) %>%
  mutate(percentage = count / sum(count) * 100)

ggplot(data = total_counts, aes(x = time_interval, y = count, fill = time_interval)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(percentage, 1), "%")),
            vjust = -0.5, size = 3) +
  labs(x = "Time interval", y = "Total usage") +
  scale_y_continuous(labels = scales::comma) + 
  theme_minimal() +
  theme(legend.position = "none")

```

@fig-difference_usage shows the result of the average daily parking volume minus the departure volume at each station. It can be observed that most stations have balanced parking and departure volumes, but some stations show significant supply-demand differences. Specifically, stations such as Bay St / Charles St W – SMART and Bay St / Wellesley St W have noticeably higher departure volumes than parking, while College St / Huron St and College St / Henry St have higher parking volumes than departure, indicating an imbalance in supply and demand at these locations.

```{r, fig.width=8, fig.height=5, fig.pos="H"}
#| label: fig-difference_usage
#| fig-cap: Difference of daily average of bicycle parking and departure volumes for each station
#| echo: false
#| message: false
#| warning: false
options(scipen = 999)


# Create a new column for the time interval (every 1day)
start_1day <- start %>%
  mutate(date = as.Date(time))
stop_1day <- stop %>%
  mutate(date = as.Date(time))
start_1day <- start_1day %>% select(-time)
stop_1day <- stop_1day %>% select(-time)

# Group by from(to)_station_name and the new interval, then count the occurrences
start_1day1 <- start_1day %>%
  group_by(station_name, date) %>%
  summarise(total_count = sum(count), .groups = "drop") %>%
  ungroup()
stop_1day1 <- stop_1day %>%
  group_by(station_name, date) %>%
  summarise(total_count = sum(count), .groups = "drop") %>%
  ungroup()


average_counts_start <- start_1day1 %>%
  group_by(station_name) %>%
  summarize(average_count = mean(total_count, na.rm = TRUE))

average_counts_stop <- stop_1day1 %>%
  group_by(station_name) %>%
  summarize(average_count = mean(total_count, na.rm = TRUE))

merged_data <- merge(average_counts_start, average_counts_stop, by.x = "station_name", by.y = "station_name", all = TRUE)


merged_data <- merged_data %>%
  mutate(count_difference = ifelse((average_count.y - average_count.x) >= 0, 
                                   ceiling(average_count.y - average_count.x), 
                                   floor(average_count.y - average_count.x)))


ggplot(merged_data, aes(x = station_name, y = count_difference)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(
       x = "Station Name",
       y = "Parking volume minus departure volume")+
  ylim(-4, 3)+
  coord_flip()
```

# Model {#sec-model}
In the process of model development, this study utilized R [@citeR] and the following R packages:brms[@brms] and rstanarm[@rstanarm] were used for model construction. bayesplot[@bayesplot], tidyverse[@tidyverse], ggplot2[@ggplot2], knitr[@knitr], and kableExtra[@kableExtra] were used for verifying model assumptions and model validation.

## Model descriptions
Equation\ref{eq:poisson} is the model used in this study:

\begin{equation}
\begin{aligned}
    \text{count} &\sim \text{Poisson}(\lambda) \\
    \log(\lambda) &= \beta_0 + \beta_1 \times \text{hour} + \beta_2 \times \text{day} + \beta_3 \times \text{month} + \beta_4 \times \text{year} \\
    \beta_0 &\sim \mathcal{N}(0, 5) \\
    \beta_j &\sim \mathcal{N}(0, 2) \quad \text{for } j = 1, 2, 3, 4
\end{aligned}
\label{eq:poisson}
\end{equation}

This study employs a Bayesian linear Poisson model to predict the variable `count`, which represents the expected number of bike-sharing usage events at a specific station on the St. George campus of the University of Toronto within a future 4-hour interval. The `count` is assumed to follow a $\text{Poisson}(\lambda)$ distribution, where $\log(\lambda)$ is the logarithmic transformation of the count. This transformation provides a simpler and more stable way to describe the relationship between the `count` and its influencing factors.

The predictors used in this model are as follows:
\begin{itemize}
  \item year: The year of the time being predicted.
  \item month: The month of the time being predicted.
  \item day: The day of the month being predicted.
  \item hour: The time interval within the day being predicted. For example, a value of 12 represents the 4-hour interval from the 12th hour to the 16th hour in a 24-hour day.
\end{itemize}

The intercept $\beta_0$ represents the baseline level of the response variable `count` when all predictors (`year`, `month`, `day`, and `hour`) are zero. A relatively broad prior distribution, $\mathcal{N}(0, 5)$, is assigned to $\beta_0$ due to the lack of strong prior knowledge about the baseline demand. This allows the model to flexibly learn the actual baseline demand from the data. Additionally, given the potential for significant variability in baseline usage levels at different times, the broad prior ensures that the model can account for this uncertainty effectively.

For the coefficients $\beta_1, \beta_2, \beta_3, \beta_4$, which correspond to the predictors `hour`, `day`, `month`, and `year`, a narrower prior distribution, $\mathcal{N}(0, 2)$, is used. This reflects the assumption that the effects of these variables on `count` are likely to be moderate and within a reasonable range. The smaller standard deviation imposes stronger constraints on these effects, preventing them from causing unrealistic shifts in the predictions. At the same time, the prior remains flexible enough to allow the model to learn the actual effects of these time-related factors on demand patterns from the data.

This study employs the Poisson model, which assumes that the events under investigation are discrete and countable, occurring within a fixed time or spatial interval. Furthermore, it assumes that the occurrences of events are independent of each other, and the average rate of occurrence ($\lambda$) remains constant over the specified interval. Lastly, it is assumed that at most one event can occur within an extremely short time or spatial interval. These assumptions enable the Poisson distribution to effectively describe the probabilistic characteristics of the events.

The model was chosen based on the nature of the variable *count*, as this study hypothesizes that a Poisson distribution may better explain its discrete and non-negative characteristics. The selection of predictors is informed by the data structure: *year* is included to capture the overall upward trend over time, *month* and *day* account for seasonal variations, and *hour* reflects daily usage differences. This approach ensures that the model effectively addresses the temporal and seasonal dynamics inherent in the data.

This study considered using the ARIMA (autoregressive integrated moving average) model as an alternative but ultimately decided against it due to its limitations in capturing the specific characteristics of bike-sharing usage data. Although the ARIMA model has advantages in time series analysis, allowing for more accurate short-term predictions with parameters that have clearer interpretability. Bike-sharing usage exhibits significant seasonal patterns, time-of-day effects, and count-based characteristics, while ARIMA models are primarily suited for stationary time series with linear autocorrelations. ARIMA struggles to effectively address non-stationary trends and overdispersion, such as the marked decrease in usage during winter. Although extensions like SARIMA (Seasonal ARIMA) can account for seasonality, they still cannot directly handle the count-based nature of the data. In contrast, Bayesian Poisson regression is specifically designed for count data, allowing for the flexible integration of variables such as year, month, and specific four-hour intervals. Additionally, the Bayesian framework provides posterior distributions, offering deeper insights into parameter uncertainty and variability, which are critical for policy decisions. Therefore, Bayesian Poisson regression is more suitable for this study than the ARMA model.

## Validation
@fig-PPvsFV is the residual plot. It demonstrates several strengths of the model. First, the residuals are primarily distributed around the zero line, indicating that the model does not exhibit significant systematic bias in its predictions. This suggests that the model is generally effective at capturing the central trends of the data. Second, the residual distribution shows a consistent linear pattern, reflecting the model's stability across different levels of fitted values. This consistency implies that the model performs reliably in its predictions for various ranges of the response variable. Third, the model successfully captures localized patterns in the data, as evidenced by the structured yet controlled behavior of the residuals. 

```{r, fig.pos="H"}
#| label: fig-PPvsFV
#| fig-cap: Pearson Residuals vs Fitted Values
#| echo: false
#| message: false
#| warning: false
options(scipen = 999)
poisson_glm <- readRDS(here::here("models/College_St___Huron_St.rds"))
data <- read_parquet(here::here("data/02-analysis_data/start.parquet")) %>% filter(station_name == "Galbraith Rd / King's College Rd
")%>%
    mutate(
      hour = hour(time),
      day = day(time),
      month = month(time),
      year = year(time)
    )

# 1. Residual diagnostics
# Extract residuals
pearson_residuals <- residuals(poisson_glm, type = "pearson")
deviance_residuals <- residuals(poisson_glm, type = "deviance")

# Plot residuals vs fitted values
ggplot(data, aes(x = fitted(poisson_glm), y = pearson_residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Fitted Values", y = "Pearson Residuals")

```
@fig-PPplot is the posterior predictive check plot. The posterior predictive check plot highlights several strengths of the model. The predicted distribution ($y_{rep}$) closely aligns with the observed distribution ($y$), particularly at the primary density peak near 0 and the secondary peaks within the 2-5 range, indicating that the model effectively captures the overall data distribution. Additionally, the model successfully reflects the multimodal nature of the data, accurately identifying multiple peaks, which demonstrates its capability to handle complex data patterns. The tail behavior of the predicted distribution is also consistent with the observed distribution, showing that the model performs well in accounting for rare or extreme events. Furthermore, the uncertainty of the predicted distribution is appropriately moderate, neither too narrow to indicate overconfidence nor too wide to suggest excessive variability. 

```{r, fig.pos="H"}
#| label: fig-PPplot
#| fig-cap: Posterior Predictive Checks
#| echo: false
#| message: false
#| warning: false
# 5. Posterior Predictive Checks
pp_check(poisson_glm, plotfun = "dens_overlay", nreps = 100) +
  labs(
    x = "Usage",  
    y = "Estimated density"         
  ) +
   yaxis_text()
```
The credible intervals shown in @tbl-crediinte highlight several strengths of the model. Key variables such as hour, month, and year have narrow credible intervals that do not include zero, indicating their significant and consistent influence on the response variable. This demonstrates the model’s ability to effectively capture critical trends and relationships in the data, particularly those related to time and seasonal effects. Additionally, the relatively small width of these intervals reflects the stability and reliability of parameter estimates, suggesting that the model is well-calibrated and robust in its predictions. The intercept, while having a broader credible interval, provides a reasonable baseline estimate, reflecting the overall level of the response variable.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-crediinte
#| tbl-cap: "Credible intervals"
posterior_draws <- as.matrix(poisson_glm)

# Compute credible intervals
credible_intervals <- apply(posterior_draws, 2, function(x) quantile(x, probs = c(0.025, 0.975)))

# Convert to data frame for display
credible_intervals_df <- t(credible_intervals)  # Transpose to match the desired layout

# Display as a table
kable(credible_intervals_df, format = "html", digits = 2, align = "c",
      col.names = c("2.5%", "97.5%"))
```

# Results{#sec-result}
This study ultimately predicted the usage volume of 27 shared bicycle stations within the University of Toronto's St. George campus during a 4-hour time window from 4:00 AM to 8:00 AM on September 26, 2025. The prediction was then compared to the usage volume recorded during the same period in 2024. @fig-result shows the results. 

```{r, fig.pos="H", fig.width=8, fig.height=6}
#| label: fig-result
#| fig-cap: "The actual count from 4:00 AM to 8:00 AM on September 26, 2024 vs the predicted count for the same time interval in 2025."
#| echo: false
#| message: false
#| warning: false
ut_stations <- c("Madison Ave / Bloor St W", "Bloor St W / Huron St", "St. George St / Bloor St W", 
                 "Sussex Ave / St George St", "Spadina Ave / Sussex Ave", "Spadina Ave / Harbord St - SMART",
                 "St. George St / Hoskin Ave", "Spadina Ave / Willcocks St", "St. George St / Willcocks St",
                 "Willcocks St / St. George St", "Queen's Park / Bloor St W", "Queen's Park Cres W / Hoskin Ave",
                 "Wellesley St W / Queen's Park Cres", "Queen's Park Cres E / Grosvenor St - SMART", 
                 "Bay St / Bloor St W (East Side)", "Bay St / Bloor St W (West Side)", "Bay St / Charles St W - SMART",
                 "St. Joseph St / Bay St - SMART", "Bay St / St. Joseph St", "Bay St / Wellesley St W", 
                 "Ursula Franklin St / Huron St - SMART", "Ursula Franklin St / St. George St - SMART", "Galbraith Rd / King's College Rd",
                 "College St / Huron St", "College St / Henry St ", "Queens Park Cres / College St ", "University Ave / College St (East)")

result <- data_frame(station_name = ut_stations, time = as.POSIXct("2025-09-26 04:00:00", format = "%Y-%m-%d %H:%M:%S"))

for (station in ut_stations) {
  station_data <- subset(start, station_name == station)
  path <- paste(paste0("models/", gsub("[ /]", "_", station), ".rds"))
  md <- readRDS(here::here(path))
  target <- data_frame(
    hour = 4,
    day = 26,
    month = 9,
    year = 2026
  )
  target$predicted <- ceiling(exp(predict(md, newdata = target)))
  target$station_name <- station
  target <- target %>% select(-hour,-day,-month,-year)
  result[result$station_name == station, "prediction"] <- target$predicted
}

data2024 <- start
for (station in ut_stations) {
  date <- "2024-09-26 04:00:00"
  exists <- nrow(data2024[data2024$station_name == station & data2024$time == date, ]) > 0
  
  if (!exists) {
    new_row <- data.frame(
      station_name = station,
      time = date,
      count = 0
    )
    data2024 <- rbind(data2024, new_row)
  }
}

data2024 <- data2024[data2024$time == "2024-09-26 04:00:00", ]

names(result)[names(result) == "time"] <- "target_time"


data_fi <- merge(data2024, result, by = "station_name")

data_fi$growth <- data_fi$prediction - data_fi$count

# Reshape data to long format
data_long <- data_fi %>%
  pivot_longer(cols = c(count, prediction), names_to = "Note", values_to = "value")

# Create the plot
ggplot(data_long, aes(x = station_name, y = value, fill = Note)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7), width = 0.7) +
  geom_text(aes(label = value), 
            position = position_dodge(width = 0.7), 
            vjust = -0.5, 
            size = 3) + 
  labs(
    x = "Station Name",
    y = "Usage",
  ) +
  scale_fill_manual(
    values = c("count" = "pink", "prediction" = "skyblue"),
    labels = c("count" = "Actual count in 2024", "prediction" = "Predicted count in 2025") 
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```
The prediction indicates an average increase of 2 uses per station across the 27 shared bike stations between 4:00 AM and 8:00 AM on September 26, 2025, compared to the same period in 2024. Specifically, 8 stations are projected to see an increase of 3 uses, 14 stations an increase of 2 uses, and 3 stations an increase of 1 use. Meanwhile, one station is expected to experience no change, and another is forecasted to see a decrease of 1 use. 

# Discussion{#sec-discussion}

## Optimization Suggestions for Campus Bike-Sharing Systems

This study identifies significant patterns in the use of bike-sharing systems on the University of Toronto’s St. George campus, including temporal, seasonal, and annual trends. The findings reveal that 79.8% of bike usage occurs between 8 AM and 8 PM, while demand between midnight and 8 AM is minimal. This highlights the strong alignment between bike usage and users’ daily routines. To improve commuting efficiency, it is recommended that the university collaborates with the bike-sharing provider to increase bike availability during peak hours (e.g., before and after class times) and optimize station layouts, particularly in high-demand areas such as dormitories, academic buildings, and transit hubs. During low-demand hours (e.g., early morning), maintenance and redistribution efforts can be scheduled to ensure the availability of bikes during peak periods.

Seasonal data also show that bike usage significantly decreases during winter, approaching zero, while increasing steadily during spring and summer, peaking in August and September during the start of the academic year. This suggests the need for proactive and dynamic adjustments in bike supply. During the start of the academic year, expanding station capacity and offering user-friendly navigation services can help new and returning students quickly familiarize themselves with the system. In winter, efforts should focus on improving station infrastructure (e.g., anti-freeze facilities) and maintaining safety under cold conditions. Additionally, by leveraging predictive analytics to forecast station-specific demand fluctuations, resources can be optimized in advance, minimizing inconveniences caused by bike shortages or overcrowded parking during peak times.

## This Study Provides a Research Methodology for Shared Bikes in Semi-Closed Areas

This study provides actionable recommendations for improving user experience in semi-closed environments like university campuses. Unlike urban open systems, bike usage in campuses is strongly influenced by fixed schedules such as class timings and campus events. This approach can be further extended to other similar semi-closed areas, such as industrial parks, manufacturing facilities, and residential complexes, where movement patterns are often dictated by predictable schedules, shifts, or local routines.

In these environments, bike-sharing systems can be optimized to align with peak demand periods, such as shift changes in factories, scheduled breaks in office parks, or recreational times in residential areas. By leveraging predictive analytics and data-driven insights, administrators can strategically allocate bikes and docking stations to match demand patterns, ensuring users have access when and where they need it most.

Moreover, this methodology is cost-effective. By targeting specific time windows and locations with higher demand, resources can be distributed more efficiently, reducing waste and operational costs. This reduces the need for large-scale deployment of bikes and infrastructure, which is often necessary in open urban systems. Instead, investments can be focused on key high-demand areas within these semi-closed environments, maximizing return on investment while enhancing user satisfaction.


## Limitations
This study employs a Bayesian Poisson regression model, which, while advantageous for handling count data, has significant limitations due to its assumptions. The Poisson model assumes that bike usage events are independent of one another, ignoring interactions among user behaviors, such as multiple users arriving at a station simultaneously during peak hours. Additionally, the model presumes a constant usage rate within each time period, which fails to capture dynamic fluctuations in reality, such as those caused by weather changes or campus events.

The study only considers temporal variables (e.g., year, month, day, and hour) and excludes other critical external factors, significantly limiting the accuracy of its predictions. Weather conditions, for instance, have a substantial impact on bike usage; rainy, snowy, or extremely hot or cold days see a marked decline in usage frequency. Moreover, special events on campus and holidays directly affect bike demand. Neglecting these external factors prevents the model from accurately capturing fluctuations in actual demand.

The handling of temporal variables in the model is relatively simplistic, overlooking potential complex interactions among these variables, which restricts the predictive performance. Poisson regression struggles to adequately address the high concentration of demand during peak periods, potentially underestimating peak usage. Consequently, more sophisticated and flexible models, such as random forests or deep learning approaches, may be better suited to capturing these intricate relationships and improving prediction accuracy.

The study also falls short in validating the model's generalization capability. Although residual analysis and posterior predictive checks were used to evaluate model fit, there was no assessment of the model's predictive performance on unseen data, such as cross-validation or evaluation in different scenarios. Broader validation would enhance the model's robustness and reliability in practical applications.

Additionally, choices made during the data cleaning process may affect the accuracy of the study's results. Excluding data from 2015–2016 improved data consistency but may have overlooked long-term trends in the evolution of the bike-sharing system. Furthermore, the way outliers and missing values were handled during data cleaning could significantly influence the model's outcomes. A lack of systematic and precise data standardization could lead to inconsistent model performance across data from different years, thereby affecting the reliability and accuracy of the predictions.

## Suggestions for Future Research
While this study successfully predicts bike-sharing usage at the University of Toronto's St. George campus, several areas warrant further exploration to enhance the reliability and applicability of the results.

First, expanding the dataset to include additional environmental variables could provide deeper insights. Incorporating factors such as weather conditions, traffic congestion data, and socioeconomic variables could improve the model's accuracy, especially for predicting daily or hourly usage variations. Future studies could also include other campus transportation modes to enable a more comprehensive analysis of mobility patterns within the campus.

Additionally, this research is limited to employing Bayesian Poisson regression. Exploring more advanced machine learning methods, such as random forests or neural networks, could improve prediction accuracy by capturing the nonlinear relationships among factors influencing bike-sharing usage.

Another potential avenue for future research is extending the study beyond the campus. Comparing usage patterns across multiple university campuses could uncover broader trends and differences in bike-sharing demand. Such comparative analyses would help researchers and policymakers determine whether the usage patterns observed at the University of Toronto are unique or represent generalizable phenomena across other campuses.


\newpage


\appendix
# Appendix {-}

# Data collection methodology
## Overview
Bike Share Toronto is the largest bike-sharing service provider in the Greater Toronto Area, committed to promoting gas-free transportation since its establishment. Starting with 79 stations in 2014, the system has expanded rapidly over the past decade. As of September 2024, the number of stations has grown to 855, capturing the entire bike-sharing market in Toronto [@liu2023bike].

Bike Share Toronto uses its advanced bike-sharing system to automatically collect and manage ride data. Each bike and docking station is equipped with sensors and communication devices to record trip data in detail. This data is transmitted in real time to a central database via a wireless network, used for system monitoring, operational maintenance, and user behavior analysis. To support academic research and urban planning, Bike Share Toronto also anonymizes the data and makes it publicly available. This dataset includes all ride records since the system's inception and is therefore considered a population rather than a sample.

With ongoing system and technological updates, the data collected and published each year varies. Data from 2014-2015 primarily captured hourly usage on weekdays and weekends. Starting in 2016, more detailed data was collected, including trip start and end stations, start and end times, trip duration, trip ID, and user type. From 2017 to 2023, the data was further refined with the addition of unique identifiers for each station (station ID). In 2024, information on bike models was added. The data release cycle also varied across different periods, with some data released quarterly and others monthly. Despite the consistency in the recorded content each year, variable names differ.

## Evaluation
In evaluating the data collection methods, I focused on accuracy, completeness, consistency, and relevance to ensure the credibility and scientific quality of the research. Below is a detailed assessment of the Bike Share Toronto dataset:

**Accuracy**  
Bike Share Toronto records ride data in real time through sensors and communication devices, an automated collection method that effectively reduces errors associated with manual recording. Additionally, data is directly stored in a central database and updated in real time, enhancing accuracy. However, sensor devices may be subject to hardware failures or communication interruptions, leading to minor data loss or errors. Although such occurrences are rare, they need to be addressed during data preprocessing.

**Completeness**  
The dataset covers all ride records since 2014, with data variables expanding as the system and technology improved. This historical and comprehensive nature allows the data to reflect long-term trends in Toronto's bike-sharing system. However, the limited variables in early data (e.g., only hourly usage for 2014-2015) require researchers to be mindful of inconsistencies across years, and early data may need supplementation or transformation to meet research needs.

**Consistency**  
Although the Bike Share Toronto dataset has expanded annually with new variables, changes in variable names can pose challenges for data analysis. For instance, some variables have been named differently across different years, requiring standardization during data cleaning. Additionally, the variation in data release cycles (quarterly or monthly) could affect the continuity of time series analysis, necessitating data resampling or aggregation to ensure consistency.

**Relevance**  
The detailed variables in the dataset (such as station ID, ride duration, and user type) provide opportunities for multidimensional analysis, enabling researchers to explore geographic distribution, temporal patterns, and user behavior. Since the dataset represents a population rather than a sample, researchers have greater flexibility in their study focus, ranging from micro-level user behavior to macro-level trend analysis. However, this comprehensiveness also increases the difficulty of data cleaning, such as dealing with redundant data, outliers, and the computational burden of large-scale data processing. Moreover, anonymization protects user privacy, it may limit certain studies focusing on micro-level user behavior.

# Idealized methodology
In an ideal research methodology, the design of data collection should emphasize comprehensiveness, systematic approach, and relevance, ensuring that the collected data can adequately reflect the multidimensional characteristics of the research subject. Specifically, in addition to core data from the bike-sharing system (such as ride duration, start and end stations, riding time, etc.), external environmental factors should also be considered, including weather conditions (temperature, precipitation, wind speed), holiday information (whether it is a public holiday, behavioral changes before and after holidays), traffic flow (interactions between shared bikes, motor vehicles, and public transportation), and socio-economic factors of the region (income levels, population density, and urbanization degree of different communities). These external variables provide richer contextual information for data analysis, thereby supporting more precise research conclusions.

Moreover, the comprehensiveness of data collection should not only reflect the diversity of variables but also consider continuity in temporal and spatial dimensions. Ideally, the data should cover the full-year operation of all stations in the bike-sharing system, with high-frequency recording (e.g., per minute or second) of trip dynamic data to avoid biases or misinterpretations due to data loss. A unified data format and standardized naming conventions should be adopted to ensure compatibility between different time periods and various data sources, thereby achieving seamless data integration.

To address potential information gaps caused by facility malfunctions, several solutions can be implemented: firstly, multiple data collection devices should be integrated into the system to minimize the impact of a single device failure on overall data integrity. For instance, sensors on bicycles can serve as backups for station records, ensuring that even if one side fails, the other can still provide critical data. Secondly, the central database can be designed to automatically fill in missing data using mechanisms such as utilizing historical data, average values from neighboring stations, or similar time periods, thus reducing the impact of information gaps on the analysis results.

## Ideal Dataset Framework
A well-designed ideal dataset framework should be comprehensive, flexible, and structured, enabling multidimensional analysis and dynamic scalability. Below is the proposed framework for a bike-sharing system dataset:

**Temporal Dimensions**

- Date: Year/Month/Day, supporting time-series analysis.

- Timestamp: Precise to the second, enabling high-precision analysis.

- Time Period: Categorized into morning peak, evening peak, weekdays/weekends, etc., for behavioral pattern analysis.

**Spatial Dimensions**

- Start Station ID: A unique identifier for the starting station.

- Start Station Name: Readable names for better understanding.

- End Station ID: A unique identifier for the destination station.

- End Station Name: Helps with geographic visualization.

- Latitude/Longitude: Precise coordinates for spatial analysis.

**Trip Information**

- Trip ID: A unique identifier for each trip.

- Trip Duration: Duration of the trip in seconds, indicating the trip length.

- Trip Distance: Distance traveled in meters, providing spatial context.

- Bike ID: A unique identifier for each bike.

**User Information**

- User Type: Differentiates between members and casual users.

- User Age: Estimated age range of the user, supporting demographic analysis.

- User Gender: Categorized as male, female, or other/unspecified.

**Environmental Factors**

- Weather Conditions: Includes temperature, humidity, precipitation, and wind speed.

- Air Quality Index: Provides environmental health metrics.

- Traffic Conditions: Includes road congestion index or traffic volume.

**System Status**

- Available Bikes at Start Station: Number of bikes available at the starting station at trip initiation.

- Available Docks at End Station: Number of free docks at the destination station at trip conclusion.

- Device Status: Indicates whether the equipment (e.g., sensors) is functioning properly.

**Operations and Management**

- Maintenance Records: Includes repair times and reasons for bikes and station facilities.

- Anomalies: Records equipment failures, data abnormalities, etc.

 **Data Quality**
 
- Missing Data Flag: Indicates whether data is missing or contains substituted values.

- Data Source: Records the source or method of data collection (e.g., station sensors, user applications).

@tbl-p1, @tbl-p2, @tbl-p3, @tbl-p4, @tbl-p5, @tbl-p5 show a simulation of proposed ideal dataset.
```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-p1
#| tbl-cap: "Simulated Ideal Dataset Part 1"

# Simulation function
simulate_bike_share_data <- function(n) {
  data <- data.frame(
    Date = as.Date(Sys.Date()) - sample(0:30, n, replace = TRUE),
    Timestamp = format(Sys.time() - runif(n, min = 0, max = 86400), "%Y-%m-%d %H:%M:%S"),
    Time_Period = sample(c("Morning Peak", "Evening Peak", "Weekday", "Weekend"), n, replace = TRUE),
    Start_Station_ID = sample(100:200, n, replace = TRUE),
    Start_Station_Name = paste("Station", sample(100:200, n, replace = TRUE))
  )
  return(data)
}

# Generate data
bike_share_part1 <- simulate_bike_share_data(5)

# Display first table
kable(bike_share_part1)

```

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-p2
#| tbl-cap: "Simulated Ideal Dataset Part 2"
bike_share_part2 <- data.frame(
  End_Station_ID = sample(100:200, 5, replace = TRUE),
  End_Station_Name = paste("Station", sample(100:200, 5, replace = TRUE)),
  Latitude = round(runif(5, 43.6, 43.7), 6),
  Longitude = round(runif(5, -79.4, -79.3), 6),
  Trip_ID = paste("TRIP", sample(1000:9999, 5, replace = TRUE), sep = "-")
)

# Display second table
kable(bike_share_part2)

```

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-p3
#| tbl-cap: "Simulated Ideal Dataset Part 3"
bike_share_part3 <- data.frame(
  Trip_Duration_s = sample(300:3600, 5, replace = TRUE),
  Trip_Distance_m = sample(500:10000, 5, replace = TRUE),
  Bike_ID = paste("BIKE", sample(1000:9999, 5, replace = TRUE), sep = "-"),
  User_Type = sample(c("Member", "Casual"), 5, replace = TRUE),
  User_Age = sample(18:60, 5, replace = TRUE)
)

# Display third table
kable(bike_share_part3)

```

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-p4
#| tbl-cap: "Simulated Ideal Dataset Part 4"
bike_share_part4 <- data.frame(
  Weather_Conditions = sample(c("Sunny", "Cloudy", "Rainy"), 5, replace = TRUE),
  Air_Quality_Index = sample(10:100, 5, replace = TRUE),
  Traffic_Conditions = sample(c("Low", "Moderate", "High"), 5, replace = TRUE),
  Available_Bikes_at_Start_Station = sample(0:20, 5, replace = TRUE)
)

# Display fourth table
kable(bike_share_part4)

```

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-p5
#| tbl-cap: "Simulated Ideal Dataset Part 5"
bike_share_part5 <- data.frame(
  Available_Docks_at_End_Station = sample(0:20, 5, replace = TRUE),
  Device_Status = sample(c("Operational", "Faulty"), 5, replace = TRUE),
  Maintenance_Records = sample(c("None", "Minor Repair", "Major Repair"), 5, replace = TRUE)
)

# Display fifth table
kable(bike_share_part5)


```

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-p6
#| tbl-cap: "Simulated Ideal Dataset Part 6"
bike_share_part6 <- data.frame(
  User_Gender = sample(c("Male", "Female", "Other"), 5, replace = TRUE),
  Anomalies = sample(c("None", "Sensor Error", "Docking Failure"), 5, replace = TRUE),
  Missing_Data_Flag = sample(c(TRUE, FALSE), 5, replace = TRUE),
  Data_Source = sample(c("Station Sensor", "Mobile App", "System Log"), 5, replace = TRUE)
)

# Display sixth table
kable(bike_share_part6)


```

\newpage


# References


