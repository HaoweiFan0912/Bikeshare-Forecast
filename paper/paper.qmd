---
title: "Analysis and Prediction of Shared Bicycle Usage at the University of Toronto St. George Campus"
subtitle: "Main Finding TBD"
author: 
  - Haowei Fan
thanks: "Code and data are available at: https://github.com/HaoweiFan0912/Bikeshare-Forecast.git"
date: today
date-format: long
abstract: "Students and staff at the University of Toronto's St. George campus often face difficulties finding a bike-sharing parking spot when arriving at campus, and finding a bike when leaving, which highlights the need for effective prediction of future bike-sharing demand to support campus commuting infrastructure. This study uses Bayesian Poisson regression to predict the usage of bike-sharing stations at 27 locations on campus for specific years, months, and  four-hour intervals of the day. The results indicate that, on September 26, 2025, from 4:00 to 8:00 AM, usage at 8 stations will increase by 3, 14 stations by 2, 3 stations by 1, 1 station remains unchanged, and 1 station will decrease by 1 compared to the same period in 2024."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| echo: false
#| include: false
#| warning: false
#| message: false
#### Workspace setup ####
set.seed(912)
# List of necessary packages
packages <- c("tidyverse", "dplyr", "arrow", "sf", "ggplot2", "ggspatial", "RColorBrewer", "knitr", "bayesplot", "kableExtra")
# Install missing packages
missing_packages <- packages[!(packages %in% installed.packages()[, "Package"])]
install.packages(missing_packages)
# Load packages
lapply(packages, library, character.only = TRUE)

#### Read data ####
start <- read_parquet(here::here("data/02-analysis_data/start.parquet"))
stop <- read_parquet(here::here("data/02-analysis_data/stop.parquet"))
```

# Introduction
Bike-sharing services have undoubtedly improved commuting efficiency, especially for short trips within a campus. For example, a study on bike-sharing in Xiamen, China, highlighted how data-driven analyses can inform policymakers about system performance, thereby guiding investments and policy decisions to enhance urban mobility[https://arxiv.org/abs/2401.03987?utm_source=chatgpt.com]. However, in the Toronto region, despite a study by the University of Toronto's School of Cities showing that ridership increased from about 665,000 trips in 2015 to over 4.5 million in 2022[https://schoolofcities.github.io/bike-share-toronto/growth], there has been little research focused on small-scale areas, such as universities, within Toronto. Furthermore, a study from Hangzhou, China, confirmed the significant differences in traveling characteristics between cities and university campuses[https://file.techscience.com/uploads/attached/file/20200916/20200916072445_75552.pdf?utm_source=chatgpt.com]. Therefore, this paper takes the University of Toronto as a case study to analyze bike-sharing usage within the campus.

The core of this study is to extract a sample of 27 bike-sharing stations within the University of Toronto campus from all bike-sharing usage data between January 1, 2017, and September 30, 2024. The total usage of bike-sharing at each station is calculated for each 4-hour interval. A Bayesian Poisson regression model is then employed to predict the usage based on the station, year, month, date, and the specific 4-hour interval of the day.

This study found that although the usage at all stations within the University of Toronto campus has increased rapidly each year, there are significant seasonal differences. During winter, usage at all stations, regardless of the year, remains close to zero. Additionally, from January to September each year, the usage shows an upward trend, which then gradually declines over the following months. There are also significant differences in usage across different times of the day. The period from 8 am to 8 pm accounts for an average of 79.8% of daily usage, while the period from midnight to 8 am accounts for only 6.8%. It is noteworthy that this project forecasts an average increase of 2 uses across 27 stations between 4:00 AM and 8:00 AM on September 26, 2025, compared to the same time period in 2024. Specifically, usage at 8 stations is expected to increase by 3, 14 stations by 2, and 3 stations by 1, while 1 station will remain unchanged and another will decrease by 1.


Compared to the general statistics on bike-sharing usage in the Greater Toronto Area, these findings offer more detailed recommendations specifically for transportation planning and policy adjustments within the University of Toronto campus. They also provide guidance on how to better allocate, deploy, or store shared bikes.

Structure: TBD

## Estimand
This study aims to estimate the usage of a specific bike-sharing station within the University of Toronto campus during a particular 4-hour interval. By converting time into year, month, day, and the specific 4-hour interval of the day, it accounts for the overall trend, seasonal effects, and hourly variation in station usage. The core objective is to explore the temporal changes in the usage of 27 bike-sharing stations within the campus, thereby providing policymakers with recommendations for bike allocation to improve commuting efficiency on campus.

# Data {#sec-data}

## Overview
The dataset used in this study comes from opendatatoronto [opendatatoronto], uploaded by Toronto Parking Authority and collected by Bike Share Toronto. It records every bike-sharing usage in the Toronto area from 2015 to September 30, 2024, with a total of 28,017,329 records. The variables included in the data differ across years, but they all contain the following variables: Trip ID, Trip Duration, Trip Start Station ID, Trip Start Time, Trip Start Station Location, Trip End Station ID, Trip End Time, Trip End Station Location, Bike ID, and User Type.

This study follows the workflow of Telling Stories with Data [Telling Stories with Data], using its initial folder structure and part of its code. Data downloading, cleaning, modeling, and visualization were carried out using R [R]. The following R libraries were also used alongside R:

TBD

## Measurement
	
To predict the relationship between bike-sharing usage and time within the University of Toronto's St. George campus, this study requires a time series to describe the changes in usage at different stations over time. Therefore, the dataset published by opendatatoronto [opendatatoronto], which records every instance of bike-sharing usage in the Toronto area since 2015, is ideal for this study. Additionally, this data is ideal because of its reliabilityâ€”due to the commercial nature of bike-sharing, the specific time and location of each bike's use and return are accurately recorded. However, the raw data cannot be used directly in this project; sophisticated data cleaning is required, with specific steps and reasons as follows:

First, data from 2015-2016 was excluded because the collection and recording methods for those years differ significantly from later years and do not include the time and station variables required for this study. Next, data for stations located within the University of Toronto's St. George campus was extracted from all remaining samples, and the usage of each station was calculated for every four-hour interval. Finally, the data format was standardized for subsequent analysis. The cleaned data is in the format of @tbl-cleaned_data.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-cleaned_data
#| tbl-cap: "Samples of the dataset used for analysis"
start |>
  tail() |>
  kable(booktabs = TRUE, align = "c")
```



## Variables

This study focuses on the following variables:

- `count`: The dependent variable of the study, a non-negative integer. It describes the total usage of bike-sharing at a particular station during a specific 4-hour interval.
- `time`: An independent variable representing the time interval. For example, "2024-09-29 12:00:00" represents the time interval from 12 pm to 4 pm on September 29, 2024, in a 24-hour format. The earliest `time` is "2017-01-01 00:00:00," and the latest is "2024-09-30 24:00:00."
- `station_name`: An independent variable representing the unique name of one of the 27 stations within the University of Toronto's St. George campus.

@fig-daily_usage shows the daily usage totals of 27 shared bicycle stations from January 1, 2017, to September 30, 2024. It can be observed that the overall usage exhibits a significant upward trend, particularly after 2021, where usage fluctuations increased noticeably. In 2024, several peaks in daily usage reached historical highs, indicating a substantial growth in user demand. Additionally, the data displays some seasonal variations, with noticeable declines during the winter months and increases during spring and summer.
```{r, fig.pos="H"}
#| label: fig-daily_usage
#| fig-cap: Daily usage from January 2017 to September 2024
#| echo: false
#| message: false
#| warning: false
start_asdate <- start 
start_asdate$time <- as.Date(start_asdate$time)
daily_counts <- start_asdate %>%
  group_by(time) %>%
  summarise(total_count = sum(count))
ggplot(data = daily_counts, aes(x = time, y = total_count)) +
  geom_point() +
  labs(x = "Time", y = "Count") +
  theme_minimal()+  
  geom_smooth(method = "lm")  
```

hows the total usage and percentage of shared bicycles during different time intervals in a day from January 1, 2017, to September 30, 2024. It can be observed that the peak usage occurs between 12:00 to 16:00 (28.5%) and 16:00 to 20:00 (31.4%). The usage between 08:00 to 12:00 accounts for 19.9%, while the usage from 20:00 to 00:00 accounts for 13.4%. The time intervals with the lowest usage are 00:00 to 04:00 (3.6%) and 04:00 to 08:00 (3.2%).

```{r, fig.pos="H"}
#| label: fig-timely_usage
#| fig-cap: Total usage during different time periods from January 2017 to September 2024
#| echo: false
#| message: false
#| warning: false
options(scipen = 999)

start_astime <- start 
start_astime$time <- as.POSIXct(start_astime$time)


start_astime <- start_astime %>%
  mutate(time_interval = case_when(
    hour(time) >= 0 & hour(time) < 4 ~ "00:00 - 04:00",
    hour(time) >= 4 & hour(time) < 8 ~ "04:00 - 08:00",
    hour(time) >= 8 & hour(time) < 12 ~ "08:00 - 12:00",
    hour(time) >= 12 & hour(time) < 16 ~ "12:00 - 16:00",
    hour(time) >= 16 & hour(time) < 20 ~ "16:00 - 20:00",
    hour(time) >= 20 & hour(time) < 24 ~ "20:00 - 00:00"
  ))


total_counts <- start_astime %>%
  group_by(time_interval) %>%
  summarise(count = sum(count, na.rm = TRUE)) %>%
  mutate(percentage = count / sum(count) * 100)

ggplot(data = total_counts, aes(x = time_interval, y = count, fill = time_interval)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(percentage, 1), "%")), 
            vjust = -0.5, size = 3) + 
  labs(x = "Time interval", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none")
```

@fig-difference_usage shows the result of the average daily parking volume minus the departure volume at each station. It can be observed that most stations have balanced parking and departure volumes, but some stations show significant supply-demand differences. Specifically, stations such as Bay St / Charles St W â€“ SMART and Bay St / Wellesley St W have noticeably higher departure volumes than parking, while College St / Huron St and College St / Henry St have higher parking volumes than departure, indicating an imbalance in supply and demand at these locations.

```{r, fig.width=8, fig.height=5, fig.pos="H"}
#| label: fig-difference_usage
#| fig-cap: Difference of daily average of bicycle parking and departure volumes for each station
#| echo: false
#| message: false
#| warning: false
options(scipen = 999)


# Create a new column for the time interval (every 1day)
start_1day <- start %>%
  mutate(date = as.Date(time))
stop_1day <- stop %>%
  mutate(date = as.Date(time))
start_1day <- start_1day %>% select(-time)
stop_1day <- stop_1day %>% select(-time)

# Group by from(to)_station_name and the new interval, then count the occurrences
start_1day1 <- start_1day %>%
  group_by(station_name, date) %>%
  summarise(total_count = sum(count), .groups = "drop") %>%
  ungroup()
stop_1day1 <- stop_1day %>%
  group_by(station_name, date) %>%
  summarise(total_count = sum(count), .groups = "drop") %>%
  ungroup()


average_counts_start <- start_1day1 %>%
  group_by(station_name) %>%
  summarize(average_count = mean(total_count, na.rm = TRUE))

average_counts_stop <- stop_1day1 %>%
  group_by(station_name) %>%
  summarize(average_count = mean(total_count, na.rm = TRUE))

merged_data <- merge(average_counts_start, average_counts_stop, by.x = "station_name", by.y = "station_name", all = TRUE)


merged_data <- merged_data %>%
  mutate(count_difference = ifelse((average_count.y - average_count.x) >= 0, 
                                   ceiling(average_count.y - average_count.x), 
                                   floor(average_count.y - average_count.x)))


ggplot(merged_data, aes(x = station_name, y = count_difference)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(
       x = "Station Name",
       y = "Parking volume minus departure volume")+
  ylim(-4, 3)+
  coord_flip()
```

# Model
The model used in this study is as follows:

\begin{equation*}
\begin{aligned}
    \text{count} &\sim \text{Poisson}(\lambda) \\
    \log(\lambda) &= \beta_0 + \beta_1 \times \text{hour} + \beta_2 \times \text{day} + \beta_3 \times \text{month} + \beta_4 \times \text{year} \\
    \beta_0 &\sim \mathcal{N}(0, 5) \\
    \beta_j &\sim \mathcal{N}(0, 2) \quad \text{for } j = 1, 2, 3, 4
\end{aligned}
\end{equation*}

This study employs a Bayesian linear Poisson model to predict the variable `count`, which represents the expected number of bike-sharing usage events at a specific station on the St. George campus of the University of Toronto within a future 4-hour interval. The `count` is assumed to follow a $\text{Poisson}(\lambda)$ distribution, where $\log(\lambda)$ is the logarithmic transformation of the count. This transformation provides a simpler and more stable way to describe the relationship between the `count` and its influencing factors.

The predictors used in this model are as follows:
\begin{itemize}
  \item year: The year of the time being predicted.
  \item month: The month of the time being predicted.
  \item day: The day of the month being predicted.
  \item hour: The time interval within the day being predicted. For example, a value of 12 represents the 4-hour interval from the 12th hour to the 16th hour in a 24-hour day.
\end{itemize}

The intercept $\beta_0$ represents the baseline level of the response variable `count` when all predictors (`year`, `month`, `day`, and `hour`) are zero. A relatively broad prior distribution, $\mathcal{N}(0, 5)$, is assigned to $\beta_0$ due to the lack of strong prior knowledge about the baseline demand. This allows the model to flexibly learn the actual baseline demand from the data. Additionally, given the potential for significant variability in baseline usage levels at different times, the broad prior ensures that the model can account for this uncertainty effectively.

For the coefficients $\beta_1, \beta_2, \beta_3, \beta_4$, which correspond to the predictors `hour`, `day`, `month`, and `year`, a narrower prior distribution, $\mathcal{N}(0, 2)$, is used. This reflects the assumption that the effects of these variables on `count` are likely to be moderate and within a reasonable range. The smaller standard deviation imposes stronger constraints on these effects, preventing them from causing unrealistic shifts in the predictions. At the same time, the prior remains flexible enough to allow the model to learn the actual effects of these time-related factors on demand patterns from the data.

## Validation
@fig-PPvsFV is the residual plot. It can be observed that the model performs well overall in the following aspects: First, most residuals are distributed around the zero line, indicating that the model has no significant systematic bias and can effectively capture the trend of `count`. Second, the majority of residuals have small absolute values, approximately within the range of $[-2, 2]$, suggesting that the model provides reliable predictions for most samples with minimal errors. Third, there is no significant nonlinear pattern between the residuals and fitted values, such as obvious curves or systematic relationships, demonstrating that the model structure captures the key influencing factors and fits the data reasonably well. Fourth, although there are a few points with larger residuals (e.g., Pearson residuals greater than 4), their number is small, and the overall predictions are not significantly affected by these outliers, reflecting the model's robustness. Fifth, if this is a relatively simple model (e.g., linear or generalized linear model), the current results indicate that the variable selection and model design are meaningful. 

```{r, fig.pos="H"}
#| label: fig-PPvsFV
#| fig-cap: Pearson Residuals vs Fitted Values
#| echo: false
#| message: false
#| warning: false
options(scipen = 999)
poisson_glm <- readRDS(here::here("models/Galbraith_Rd___King's_College_Rd.rds"))
data <- read_parquet(here::here("data/02-analysis_data/start.parquet")) %>% filter(station_name == "Galbraith Rd / King's College Rd
")%>%
    mutate(
      hour = hour(time),
      day = day(time),
      month = month(time),
      year = year(time)
    )

# 1. Residual diagnostics
# Extract residuals
pearson_residuals <- residuals(poisson_glm, type = "pearson")
deviance_residuals <- residuals(poisson_glm, type = "deviance")

# Plot residuals vs fitted values
ggplot(data, aes(x = fitted(poisson_glm), y = pearson_residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Pearson Residuals vs Fitted Values", x = "Fitted Values", y = "Pearson Residuals")

```
@fig-PPplot is the posterior predictive check plot. It demonstrates that the model performs well in capturing the overall distribution of the observed data. Specifically, the primary density peak of the observed data ($y$) between 0 and 3 aligns closely with the predictive distributions ($y_{rep}$), indicating that the model successfully captures the main trends of the data. Additionally, the tails of the predictive distributions, particularly for values greater than 6, show a consistent pattern with the observed data. This suggests that the model is capable of reasonably approximating the low-frequency occurrences in the dataset, ensuring that the overall fit is robust across both the high-density and low-density regions. 
```{r, fig.pos="H"}
#| label: fig-PPplot
#| fig-cap: Posterior Predictive Checks
#| echo: false
#| message: false
#| warning: false
# 5. Posterior Predictive Checks
pp_check(poisson_glm, plotfun = "dens_overlay", nreps = 100) # Overlay of predictive densities
```
The model demonstrates several strengths based on the parameter estimates and confidence intervals shown in @tbl-crediinte. It successfully identifies `month` as a significant predictor, with its confidence interval excluding zero, indicating a strong and meaningful influence on the response variable. This highlights the modelâ€™s ability to capture the seasonal trends that are crucial for predicting bike-sharing demand. Additionally, the predictors (`hour`, `day`, `month`) are time-related and intuitive, making the model highly interpretable. The coefficients and confidence intervals are relatively small, reflecting stable estimates without extreme effects, which enhances the modelâ€™s robustness and generalizability. Furthermore, the insignificant effects of `hour` and `day` suggest that the model avoids overfitting by not overemphasizing less impactful predictors. The chosen priors are reasonable, allowing data to guide the posterior updates effectively, especially for identifying the critical role of `month`. Overall, the model strikes a good balance between stability, interpretability, and predictive power, making it a solid foundation for understanding and forecasting seasonal trends.

```{r}
#| warning: false
#| message: false
#| echo: false
#| label: tbl-crediinte
#| tbl-cap: "Credible intervals"
posterior_draws <- as.matrix(poisson_glm)

# Compute credible intervals
credible_intervals <- apply(posterior_draws, 2, function(x) quantile(x, probs = c(0.025, 0.975)))

# Convert to data frame for display
credible_intervals_df <- t(credible_intervals)  # Transpose to match the desired layout

# Display as a table
kable(credible_intervals_df, format = "html", digits = 8, align = "c",
      col.names = c("2.5%", "97.5%"))
```





<!-- # Results -->

<!-- Our results are summarized in @tbl-modelresults. -->

<!-- ```{r} -->
<!-- #| echo: false -->
<!-- #| eval: true -->
<!-- #| warning: false -->
<!-- #| message: false -->

<!-- library(rstanarm) -->

<!-- first_model <- -->
<!--   readRDS(file = here::here("models/first_model.rds")) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #| echo: false -->
<!-- #| eval: true -->
<!-- #| label: tbl-modelresults -->
<!-- #| tbl-cap: "Explanatory models of flight time based on wing width and wing length" -->
<!-- #| warning: false -->

<!-- modelsummary::modelsummary( -->
<!--   list( -->
<!--     "First model" = first_model -->
<!--   ), -->
<!--   statistic = "mad", -->
<!--   fmt = 2 -->
<!-- ) -->
<!-- ``` -->




<!-- # Discussion -->

<!-- ## First discussion point {#sec-first-point} -->

<!-- If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this.  -->

<!-- ## Second discussion point -->

<!-- Please don't use these as sub-heading labels - change them to be what your point actually is. -->

<!-- ## Third discussion point -->

<!-- ## Weaknesses and next steps -->

<!-- Weaknesses and next steps should also be included. -->

<!-- \newpage -->

<!-- \appendix -->

<!-- # Appendix {-} -->


<!-- # Additional data details -->

<!-- # Model details {#sec-model-details} -->

<!-- ## Posterior predictive check -->

<!-- In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows... -->

<!-- In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows...  -->

<!-- ```{r} -->
<!-- #| eval: true -->
<!-- #| echo: false -->
<!-- #| message: false -->
<!-- #| warning: false -->
<!-- #| label: fig-ppcheckandposteriorvsprior -->
<!-- #| layout-ncol: 2 -->
<!-- #| fig-cap: "Examining how the model fits, and is affected by, the data" -->
<!-- #| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"] -->

<!-- pp_check(first_model) + -->
<!--   theme_classic() + -->
<!--   theme(legend.position = "bottom") -->

<!-- posterior_vs_prior(first_model) + -->
<!--   theme_minimal() + -->
<!--   scale_color_brewer(palette = "Set1") + -->
<!--   theme(legend.position = "bottom") + -->
<!--   coord_flip() -->
<!-- ``` -->

<!-- ## Diagnostics -->

<!-- @fig-stanareyouokay-1 is a trace plot. It shows... This suggests... -->

<!-- @fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests... -->

<!-- ```{r} -->
<!-- #| echo: false -->
<!-- #| eval: true -->
<!-- #| message: false -->
<!-- #| warning: false -->
<!-- #| label: fig-stanareyouokay -->
<!-- #| fig-cap: "Checking the convergence of the MCMC algorithm" -->
<!-- #| fig-subcap: ["Trace plot", "Rhat plot"] -->
<!-- #| layout-ncol: 2 -->

<!-- plot(first_model, "trace") -->

<!-- plot(first_model, "rhat") -->
<!-- ``` -->



<!-- \newpage -->


<!-- # References -->


